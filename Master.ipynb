{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn import tree\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data/raw/20220210T003523_300-500-true-300-5000-iperf.csv')\n",
    "data2 = pd.read_csv('data/raw/20220210T003523_300-5000-true-300-500-iperf.csv')\n",
    "data3 = pd.read_csv('data/raw/20220210T010808_400-2000-true-400-2000-iperf.csv')\n",
    "data4 = pd.read_csv('data/raw/20220210T011704_500-3000-true-500-3000-iperf.csv')\n",
    "data5 = pd.read_csv('data/raw/20220210T015628_600-4000-true-600-4000-iperf.csv')\n",
    "data6 = pd.read_csv('data/raw/20220210T031531_700-4000-true-700-4000-iperf.csv')\n",
    "data7 = pd.read_csv('data/raw/20220210T032446_900-6000-true-900-6000-iperf.csv')\n",
    "data8 = pd.read_csv('data/raw/20220210T033058_1000-7000-true-1000-7000-iperf.csv')\n",
    "data9 = pd.read_csv('data/raw/20220210T063725_1100-2500-true-1100-2500-iperf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional - take out first 25 seconds of data\n",
    "data1 = data1[25:]\n",
    "data2 = data2[25:]\n",
    "data3 = data3[25:]\n",
    "data4 = data4[25:]\n",
    "data5 = data5[25:]\n",
    "data6 = data6[25:]\n",
    "data7 = data7[25:]\n",
    "data8 = data8[25:]\n",
    "data9 = data9[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset \"Time\" to arbitrary values\n",
    "data1['time'] = np.arange(len(data1))\n",
    "data2['time'] = np.arange(len(data2))\n",
    "data3['time'] = np.arange(len(data3))\n",
    "data4['time'] = np.arange(len(data4))\n",
    "data5['time'] = np.arange(len(data5))\n",
    "data6['time'] = np.arange(len(data6))\n",
    "data7['time'] = np.arange(len(data7))\n",
    "data8['time'] = np.arange(len(data8))\n",
    "data9['time'] = np.arange(len(data9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the packet loss ratio for each dataset\n",
    "packet_ratio1 = np.ones(len(data1)) * (1/5000)\n",
    "latency1 = np.ones(len(data1)) * (300)\n",
    "data1['packet_loss_ratio'] = packet_ratio1\n",
    "data1[\"latency\"] = latency1\n",
    "\n",
    "packet_ratio2 = np.ones(len(data2)) * (1/500)\n",
    "latency2 = np.ones(len(data2)) * (300)\n",
    "data2['packet_loss_ratio'] = packet_ratio2\n",
    "data2[\"latency\"] = latency2\n",
    "\n",
    "packet_ratio3 = np.ones(len(data3)) * (1/2000)\n",
    "latency3 = np.ones(len(data3)) * (400)\n",
    "data3['packet_loss_ratio'] = packet_ratio3\n",
    "data3[\"latency\"] = latency3\n",
    "\n",
    "packet_ratio4 = np.ones(len(data4)) * (1/3000)\n",
    "latency4 = np.ones(len(data4)) * (500)\n",
    "data4['packet_loss_ratio'] = packet_ratio4\n",
    "data4[\"latency\"] = latency4\n",
    "\n",
    "packet_ratio5 = np.ones(len(data5)) * (1/4000)\n",
    "latency5 = np.ones(len(data5)) * (600)\n",
    "data5['packet_loss_ratio'] = packet_ratio5\n",
    "data5[\"latency\"] = latency5\n",
    "\n",
    "packet_ratio6 = np.ones(len(data6)) * (1/4000)\n",
    "latency6 = np.ones(len(data6)) * (700)\n",
    "data6['packet_loss_ratio'] = packet_ratio6\n",
    "data6[\"latency\"] = latency6\n",
    "\n",
    "packet_ratio7 = np.ones(len(data7)) * (1/6000)\n",
    "latency7 = np.ones(len(data7)) * (900)\n",
    "data7['packet_loss_ratio'] = packet_ratio7\n",
    "data7[\"latency\"] = latency7\n",
    "\n",
    "packet_ratio8 = np.ones(len(data8)) * (1/7000)\n",
    "latency8 = np.ones(len(data8)) * (1000)\n",
    "data8['packet_loss_ratio'] = packet_ratio8\n",
    "data8[\"latency\"] = latency8\n",
    "\n",
    "packet_ratio9 = np.ones(len(data9)) * (1/2500)\n",
    "latency9 = np.ones(len(data9)) * (1100)\n",
    "data9['packet_loss_ratio'] = packet_ratio9\n",
    "data9[\"latency\"] = latency9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine datasets\n",
    "data = pd.concat([data1,data2,data3,data4,data5,data6,data7,data8,data9])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: Maximum Packet Size for each interaction\n",
    "def max_size(x):\n",
    "    \"\"\"\n",
    "    Helper function used to add max packet size feature\n",
    "    \"\"\"\n",
    "    nums = x.split(';')[:-1]\n",
    "    nums_int = list(map(int, nums))\n",
    "    return max(nums_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Range of Packet Size for each interaction\n",
    "def range_size(x):\n",
    "    \"\"\"\n",
    "    Helper function used to add range of packet size feature\n",
    "    \"\"\"\n",
    "    nums = x.split(';')[:-1]\n",
    "    nums_int = list(map(int, nums))\n",
    "    return max(nums_int) - min(nums_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Average of Packet Size for each interaction\n",
    "def avg_size(x):\n",
    "    \"\"\"\n",
    "    Helper function used to add average packet size feature\n",
    "    \"\"\"\n",
    "    nums = x.split(';')[:-1]\n",
    "    numsInt = list(map(int, nums))\n",
    "    return np.mean(numsInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 4: Average Packet Duration\n",
    "def packet_dur(x):\n",
    "    \"\"\"\n",
    "    Helper function used to add longest packet duration feature\n",
    "    \"\"\"\n",
    "    return np.mean(np.diff(list(map(int, x.split(';')[-2]))))\n",
    "    #nums = x.split(';')[:-2]\n",
    "    #numsInt = list(map(int, nums))\n",
    "    #return np.mean(np.diff(numsInt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 5: Total packet Direction\n",
    "def total_packet_dir(x):\n",
    "    \"\"\"\n",
    "    Helper function used to add total packet direction feature\n",
    "    \"\"\"\n",
    "    dirs = x.split(';')[:-1]\n",
    "    totalDirs = 0\n",
    "\n",
    "    for i in dirs:\n",
    "        if i == '1':\n",
    "            totalDirs += 1\n",
    "        elif i == '2':\n",
    "            totalDirs -= 1\n",
    "\n",
    "    return totalDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 6: total packets -> Done in apply_features()\n",
    "# Feature 7: total bytes -> Done in apply_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 8: Interaction length\n",
    "def interaction_length(x):\n",
    "    \"\"\"\n",
    "    Helper function used to add interaction length feature\n",
    "    \"\"\"\n",
    "    times = x.split(';')[:-1]\n",
    "    times2 = list(map(int, times))\n",
    "    startTime = min(times2)\n",
    "    endTime = max(times2)\n",
    "\n",
    "    return endTime - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 9: total packets over time ratio -> Done in apply_features()\n",
    "# Feature 10: total bytes over time ratio -> Done in apply_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert packet loss ratio into categorical values\n",
    "def ratio_to_category(x):\n",
    "        return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_features(df):\n",
    "    \"\"\"\n",
    "    Takes in a raw dataframe from etl.py and \n",
    "    applys all the custom features into one dataframe\n",
    "    \"\"\"\n",
    "    df['max_packet_size'] = df['packet_sizes'].apply(max_size)\n",
    "    df['range_packet_size'] = df['packet_sizes'].apply(range_size)\n",
    "    df['avg_packet_size'] = df['packet_sizes'].apply(avg_size)\n",
    "    df['avg_packet_dur'] = df['packet_times'].apply(packet_dur)\n",
    "    df['total_packet_dir'] = df['packet_dirs'].apply(total_packet_dir)\n",
    "    df['total_packets'] = df['1->2Pkts'] + df['2->1Pkts']\n",
    "    df['total_bytes'] = df['1->2Bytes'] + df['2->1Bytes']\n",
    "    df['interaction_length'] = df['packet_times'].apply(interaction_length)\n",
    "    df['packets_time_ratio'] = df['total_packets'] / df['interaction_length']\n",
    "    df['bytes_time_ratio'] = df['total_bytes'] / df['interaction_length']\n",
    "    df['packet_loss_ratio_class'] = df['packet_loss_ratio'].apply(ratio_to_category)\n",
    "    df['latency_class'] = df['latency'].apply(ratio_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply feature engineering\n",
    "apply_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify(x):\n",
    "    if x == float('inf'):\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['packets_time_ratio'] = data['packets_time_ratio'].apply(modify)\n",
    "data['bytes_time_ratio'] = data['bytes_time_ratio'].apply(modify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['time', 'total_packets', 'total_bytes', 'total_packet_dir', 'interaction_length',\n",
    "         'packets_time_ratio','bytes_time_ratio', 'avg_packet_size', 'avg_packet_dur',\n",
    "         'max_packet_size', 'range_packet_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresesion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "def linear_regression(df, features_list, y = \"packet_loss_ratio\"):\n",
    "    # Load the dataset\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    return r2_score(y_test.reset_index(drop=True), y_pred), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(linear_regression(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (coefficient of determination) regression score function\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = linear_regression(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency\n",
    "def linear_regression(df, features_list, y = \"latency\"):\n",
    "    # Load the dataset\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    return r2_score(y_test.reset_index(drop=True), y_pred), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(linear_regression(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (coefficient of determination) regression score function\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = linear_regression(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "def decision_tree(df, features_list, y = \"packet_loss_ratio_class\"):\n",
    "    # Load the dataset 'packet_sizes_var', \"Time\"\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return clf.score(X_test, y_test.reset_index(drop=True)), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(decision_tree(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean training accuracy\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = decision_tree(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency\n",
    "def decision_tree(df, features_list, y = \"latency\"):\n",
    "    # Load the dataset 'packet_sizes_var', \"Time\"\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return clf.score(X_test, y_test.reset_index(drop=True)), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(decision_tree(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean training accuracy\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = decision_tree(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency class\n",
    "def decision_tree(df, features_list, y = \"latency_class\"):\n",
    "    # Load the dataset 'packet_sizes_var', \"Time\"\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return clf.score(X_test, y_test.reset_index(drop=True)), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(decision_tree(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean training accuracy\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = decision_tree(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "def svm(df, features_list, y = \"packet_loss_ratio_class\"):\n",
    "    # Load the dataset 'packet_sizes_var', \"Time\"\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return clf.score(X_test, y_test.reset_index(drop=True)), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(svm(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean training accuracy\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = svm(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency\n",
    "def svm(df, features_list, y = \"latency\"):\n",
    "    # Load the dataset 'packet_sizes_var', \"Time\"\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return clf.score(X_test, y_test.reset_index(drop=True)), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(svm(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean training accuracy\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "#result = svm(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency class\n",
    "def svm(df, features_list, y = \"latency_class\"):\n",
    "    # Load the dataset 'packet_sizes_var', \"Time\"\n",
    "    features = features_list\n",
    "    df_X = df[features]\n",
    "    df_y = df[y]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8, random_state=42)\n",
    "\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "    # Create linear regression object\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    #print(\"Coefficients: \\n\", regr.coef_)\n",
    "    \n",
    "    # The mean squared error\n",
    "    #print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    #print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return clf.score(X_test, y_test.reset_index(drop=True)), y_test.reset_index(drop=True), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(svm(data, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean training accuracy\n",
    "scores = []\n",
    "for i in results:\n",
    "    scores.append(i[0])\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prection values vs true values\n",
    "##result = svm(data, features_list)\n",
    "#plt.plot(result[1])\n",
    "#plt.plot(result[2])\n",
    "#plt.legend([\"y_test\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
